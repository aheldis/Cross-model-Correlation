{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-08T07:32:32.109923Z",
     "iopub.status.busy": "2024-08-08T07:32:32.109644Z",
     "iopub.status.idle": "2024-08-08T07:41:01.655550Z",
     "shell.execute_reply": "2024-08-08T07:41:01.654388Z",
     "shell.execute_reply.started": "2024-08-08T07:32:32.109897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir ImageNet\n",
    "%cd ImageNet\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-08T07:44:16.710740Z",
     "iopub.status.busy": "2024-08-08T07:44:16.710066Z",
     "iopub.status.idle": "2024-08-08T07:45:18.657516Z",
     "shell.execute_reply": "2024-08-08T07:45:18.656168Z",
     "shell.execute_reply.started": "2024-08-08T07:44:16.710705Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision.models import (densenet121, densenet161, densenet169, densenet201,\n",
    "                                DenseNet121_Weights, DenseNet161_Weights,\n",
    "                                DenseNet169_Weights, DenseNet201_Weights)\n",
    "\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_layers_names(net):\n",
    "    children = []\n",
    "    for child in net.named_children():\n",
    "        if isinstance(child[1], nn.Dropout):\n",
    "            continue\n",
    "        elif isinstance(child[1], nn.ModuleList):\n",
    "            for ch in child[1]._modules:\n",
    "                children.append((child[1], child[0], ch))\n",
    "        else:\n",
    "            children.append(child[0])\n",
    "    return children\n",
    "\n",
    "\n",
    "activation = {}\n",
    "\n",
    "\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "\n",
    "    return hook\n",
    "\n",
    "\n",
    "def get_correlation(batch_size, layers1, layers2):\n",
    "    layers1 = layers1[:, 0].reshape(batch_size, -1)\n",
    "    layers2 = layers2[:, 0].reshape(batch_size, -1)\n",
    "    correlations = np.zeros_like(layers1.cpu().detach().numpy()[0])\n",
    "    for i in range(layers1.shape[1]):\n",
    "        neuron_i = layers1[:, i]\n",
    "        max_corr = -1\n",
    "        for j in range(layers2.shape[1]):\n",
    "            neuron_j = layers2[:, j]\n",
    "            stacked = torch.stack((neuron_i, neuron_j))\n",
    "            corr = torch.corrcoef(stacked)[0, 1]\n",
    "            corr = np.abs(corr.cpu().detach().numpy())\n",
    "            if corr is np.nan:\n",
    "                corr = 0\n",
    "            if corr > max_corr:\n",
    "                max_corr = corr\n",
    "        correlations[i] = max_corr\n",
    "\n",
    "    return correlations.mean()\n",
    "\n",
    "\n",
    "def mean_correlation(batch_size, layers1, layers2):\n",
    "    return (get_correlation(batch_size, layers1, layers2) + get_correlation(batch_size, layers2, layers1)) / 2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    weights = [DenseNet121_Weights.DEFAULT, DenseNet161_Weights.DEFAULT, DenseNet169_Weights.DEFAULT, DenseNet201_Weights.DEFAULT]\n",
    "    models = [densenet121(weights=weights[0]).to(device), densenet161(weights=weights[1]).to(device), densenet169(weights=weights[2]).to(device), densenet201(weights=weights[3]).to(device)]\n",
    "\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "\n",
    "    # Load ImageNet dataset\n",
    "    transform = weights[0].transforms()\n",
    "\n",
    "    imagenet_data = datasets.ImageNet('/data/ImageNet', split='val', transform=transform)\n",
    "    data_loader = DataLoader(imagenet_data, batch_size=10, shuffle=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            activations = []\n",
    "            for model in models:\n",
    "                getattr(model.features, \"transition3\").register_forward_hook(get_activation(\"transition3\"))\n",
    "                outputs = model(images)\n",
    "                activations.append(activation[\"transition3\"].detach())\n",
    "\n",
    "            for act1_i in range(len(activations)):\n",
    "                for act2_i in range(act1_i + 1, len(activations)):\n",
    "                    act1 = activations[act1_i]\n",
    "                    act2 = activations[act2_i]\n",
    "                    print(act1_i, act2_i, mean_correlation(10, act1, act2))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
